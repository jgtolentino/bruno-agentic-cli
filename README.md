# ğŸ¤– Bruno Agentic CLI

**Enhanced Local Claude Code Replacement** - A powerful AI-powered development assistant that runs entirely on your local machine using Ollama.

## âœ¨ Features

### ğŸ¯ Multiple Input Modes
- **Interactive Mode** - Guided prompts with smart agent selection
- **Command Mode** - Slash commands for quick actions
- **Free Prompt Mode** - Open-ended AI conversation

### ğŸ§  Intelligent Agent System
- **Explain Agent** - Detailed code analysis and explanations
- **Fix Agent** - Bug detection and code corrections  
- **Test Agent** - Comprehensive test generation
- **Smart Routing** - AI automatically selects the best agent

### ğŸ“ Workspace Awareness
- **Git Integration** - Automatically loads git status, branch, and recent commits
- **Project Context** - Understands your project structure and README
- **File Memory** - Tracks recently modified files
- **Context Injection** - Adds relevant workspace info to prompts

### âš¡ Advanced Features
- **Streaming Responses** - Real-time AI output with progress indicators
- **Slash Commands** - Quick `/explain`, `/fix`, `/test` commands
- **Configuration System** - Customizable via `.brunorc` file
- **Error Handling** - Graceful fallbacks and helpful error messages

## ğŸš€ Quick Start

### Prerequisites
```bash
# Install Ollama
brew install ollama

# Pull the code model
ollama pull deepseek-coder:6.7b-instruct-q4_K_M
```

### Installation
```bash
# Clone and setup
cd bruno-agentic-cli
npm install
chmod +x cli.js

# Optional: Link globally
npm link
```

### Usage
```bash
# Start Bruno
./cli.js
# or if linked globally
bruno
```

## ğŸ“‹ Slash Commands

| Command | Usage | Description |
|---------|-------|-------------|
| `/explain <file>` | `/explain src/utils.js` | Analyze and explain code |
| `/fix <file>` | `/fix components/Button.tsx` | Find and fix bugs |
| `/test <file>` | `/test lib/parser.js` | Generate unit tests |
| `/context` | `/context` | Show workspace context |
| `/model [name]` | `/model codellama:7b` | Show/change AI model |
| `/help` | `/help` | Show available commands |

## âš™ï¸ Configuration

Create a `.brunorc` file in your project root:

```json
{
  "model": "deepseek-coder:6.7b-instruct-q4_K_M",
  "ollama_host": "http://localhost:11434",
  "context_window": 4096,
  "temperature": 0.1,
  "workspace": {
    "include_git_context": true,
    "include_readme": true,
    "max_files": 50
  },
  "agents": {
    "explain": {
      "temperature": 0.2
    },
    "fix": {
      "temperature": 0.1
    },
    "test": {
      "temperature": 0.3
    }
  }
}
```

## ğŸ® Usage Examples

### Interactive Mode
```bash
./cli.js
# Select "Interactive Mode (guided prompts)"
# Choose "Smart Route (AI decides)"
# Enter: "I need help debugging this function"
# Provide file path: src/utils/parser.js
```

### Command Mode
```bash
./cli.js
# Select "Command Mode (slash commands)"
# Enter: "/explain examples/sample.js"
```

### Smart Routing Examples
- **"fix bugs in my code"** â†’ Automatically routes to Fix Agent
- **"explain this function"** â†’ Routes to Explain Agent  
- **"generate tests"** â†’ Routes to Test Agent
- **"help me understand"** â†’ Routes to Explain Agent

## ğŸ—ï¸ Architecture

```
bruno-agentic-cli/
â”œâ”€â”€ cli.js                 # Main CLI entry point
â”œâ”€â”€ .brunorc              # Configuration file
â”œâ”€â”€ agents/               # AI agent prompt templates
â”‚   â”œâ”€â”€ explain.js        # Code explanation agent
â”‚   â”œâ”€â”€ fix.js           # Bug fixing agent
â”‚   â””â”€â”€ test.js          # Test generation agent
â”œâ”€â”€ lib/                 # Core Bruno modules
â”‚   â”œâ”€â”€ slash-commands.js # Slash command parser
â”‚   â”œâ”€â”€ workspace-memory.js # Workspace context loader
â”‚   â”œâ”€â”€ router.js        # Intelligent agent routing
â”‚   â””â”€â”€ streaming.js     # Streaming response handler
â””â”€â”€ examples/            # Sample files for testing
    â””â”€â”€ sample.js
```

## ğŸ”§ Troubleshooting

### Ollama Not Running
```bash
# Start Ollama service
ollama serve

# Verify model is available
ollama list
```

### Model Issues
```bash
# Pull required model
ollama pull deepseek-coder:6.7b-instruct-q4_K_M

# Alternative models
ollama pull codellama:7b-code
ollama pull mistral:7b-code
```

### Permission Errors
```bash
# Make CLI executable
chmod +x cli.js

# Fix npm linking issues
sudo npm link
```

## ğŸ†š vs Claude Code

| Feature | Bruno CLI | Claude Code |
|---------|-----------|-------------|
| **Privacy** | âœ… 100% Local | âŒ Cloud-based |
| **Cost** | âœ… Free | ğŸ’° Paid |
| **Speed** | âœ… No network latency | âš ï¸ Depends on connection |
| **Customization** | âœ… Full control | âŒ Limited |
| **Offline** | âœ… Works offline | âŒ Requires internet |
| **Models** | âœ… Any Ollama model | âŒ Fixed models |

## ğŸ› ï¸ Development

### Adding New Agents
1. Create agent file in `agents/`
2. Implement `generatePrompt(code)` function
3. Add to router in `lib/router.js`
4. Update slash commands in `lib/slash-commands.js`

### Custom Prompts
Edit prompt templates in `agents/` or create new ones following the existing pattern.

## ğŸ“ License

MIT License - see LICENSE file for details.

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Test with various code samples
5. Submit a pull request

---

**Bruno CLI** - Your local AI coding assistant, no cloud required! ğŸš€