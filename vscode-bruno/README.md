# Bruno VS Code Extension

**Claude-style AI assistant that runs 100% locally in VS Code**

## ğŸš€ Features

- **ğŸ§  Context-Aware AI** - Automatically analyzes your current file and provides relevant suggestions
- **ğŸ›  Smart Commands** - Explain code, fix bugs, generate tests, and refactor with one click
- **ğŸ’¬ Interactive Sidebar** - Chat with Bruno directly in VS Code
- **ğŸ“š Session Memory** - Continue conversations across coding sessions
- **ğŸ”’ 100% Private** - All processing happens locally with Ollama
- **âš¡ Fast & Efficient** - Optimized for developer workflows

## ğŸ“¦ Installation

### Prerequisites

1. **Ollama** must be installed and running:
   ```bash
   # macOS
   brew install ollama
   ollama serve
   
   # Linux
   curl -fsSL https://ollama.ai/install.sh | sh
   ollama serve
   ```

2. **DeepSeek Coder model** (recommended):
   ```bash
   ollama pull deepseek-coder:6.7b
   ```

### Install Extension

1. **From VSIX file** (recommended):
   ```bash
   code --install-extension bruno-vscode-3.1.0.vsix
   ```

2. **From source**:
   ```bash
   cd vscode-bruno
   npm install
   npm run package
   code --install-extension bruno-vscode-3.1.0.vsix
   ```

## ğŸ¯ Usage

### Context Menu Commands

Right-click any file or selection:
- **ğŸ§  Bruno: Explain Current File** - Get detailed explanation
- **ğŸ›  Bruno: Fix Current File** - Find and fix issues
- **ğŸ§ª Bruno: Generate Tests** - Create unit tests
- **â™»ï¸ Bruno: Refactor Selection** - Improve selected code

### Command Palette

Press `Cmd+Shift+P` (or `Ctrl+Shift+P`):
- `Bruno: Ask Custom Prompt` - Ask anything
- `Bruno: Show Sessions` - View conversation history
- `Bruno: Continue Last Session` - Resume previous chat

### Keyboard Shortcuts

- `Cmd+Shift+B` (Mac) / `Ctrl+Shift+B` (Windows/Linux) - Quick prompt

### Interactive Sidebar

Click the Bruno icon in the activity bar to open the chat sidebar:
- Type questions directly
- View conversation history
- Access slash commands
- Manage sessions

## âš™ï¸ Configuration

Configure Bruno in VS Code settings (`Cmd+,`):

```json
{
  "bruno.model": "deepseek-coder:6.7b",
  "bruno.ollamaUrl": "http://127.0.0.1:11434",
  "bruno.contextDepth": 3,
  "bruno.showNotifications": true,
  "bruno.autoSaveSession": true
}
```

### Available Settings

- **`bruno.model`** - Ollama model to use (default: `deepseek-coder:6.7b`)
- **`bruno.ollamaUrl`** - Ollama API endpoint (default: `http://127.0.0.1:11434`)
- **`bruno.contextDepth`** - Number of conversation turns to remember (default: 3)
- **`bruno.showNotifications`** - Show popup notifications (default: true)
- **`bruno.autoSaveSession`** - Auto-save conversations (default: true)

## ğŸ’¡ Examples

### Explain Code
```
Right-click on any file â†’ "ğŸ§  Bruno: Explain Current File"
```

### Fix Bugs
```
Right-click â†’ "ğŸ›  Bruno: Fix Current File"
Bruno will analyze and offer to apply fixes
```

### Generate Tests
```
Right-click â†’ "ğŸ§ª Bruno: Generate Tests"
Bruno creates comprehensive unit tests
```

### Refactor Code
```
Select code â†’ Right-click â†’ "â™»ï¸ Bruno: Refactor Selection"
```

### Custom Prompts
```
Cmd+Shift+B â†’ "How do I optimize this React component?"
```

## ğŸ”§ Troubleshooting

### Bruno not responding?

1. Check Ollama is running:
   ```bash
   curl http://127.0.0.1:11434/api/tags
   ```

2. Verify model is installed:
   ```bash
   ollama list
   ```

3. Check VS Code Developer Tools:
   ```
   Help â†’ Toggle Developer Tools â†’ Console
   ```

### Performance issues?

- Try a smaller model: `ollama pull llama2:7b`
- Reduce context depth in settings
- Close other Ollama sessions

## ğŸ¤ Contributing

1. Fork the repository
2. Create your feature branch
3. Commit your changes
4. Push to the branch
5. Create a Pull Request

## ğŸ“„ License

MIT License - see LICENSE file

## ğŸ™ Credits

Built on top of Bruno CLI v3.1 with patterns from:
- Cursor IDE
- Windsurf Cascade
- Bolt.new
- Manus

---

Made with â¤ï¸ by InsightPulse AI